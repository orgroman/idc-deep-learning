{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 3\n",
    "All previous instructions hold. In addition, if you are using GPU, you must check that your code also runs on a CPU. \n",
    "\n",
    "**Make sure you use the best practices you learned in class**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T06:20:09.812636Z",
     "start_time": "2022-11-03T06:20:07.956326Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Convolutional Neural Network - Classifiying CIFAR-10 (40 points)\n",
    "\n",
    "So far we had to manually implement both the forward and backward passes of our neural network. Manually implementing the backward pass is not a big deal for a small two-layer network, but can quickly get very messy for large complex networks.\n",
    "\n",
    "Thankfully, we can use **automatic differentiation** to automate the computation of backward passes in neural networks. The autograd package in PyTorch provides exactly this functionality. When using autograd, the forward pass of your network will define a computational graph. Nodes in the graph will be Tensors,\n",
    "and edges will be functions that produce output Tensors from input Tensors. Backpropagating through this graph then allows you to easily compute gradients.\n",
    "\n",
    "If we want to compute gradients with respect to some Tensor, then we set `requires_grad=True` when constructing that Tensor. Any PyTorch operations on that Tensor will cause a computational graph to be constructed, allowing us to later perform backpropagation through the graph. If `x` is a Tensor with `requires_grad=True`, then after backpropagation `x.grad` will be another Tensor holding the gradient of `x`.\n",
    "\n",
    "Sometimes you may wish to prevent PyTorch from building computational graphs when performing certain operations on Tensors with `requires_grad=True`; for example, we usually don't want to backpropagate through the weight update steps when evaluating a neural network. In such scenarios we can use the `torch.no_grad()` context manager to prevent the construction of a computational graph.\n",
    "\n",
    "In this exercise, you will accomplish the following:\n",
    "1. Train a convolutional network using PyTorch.\n",
    "2. Evaluate your model using a confusion matrix.\n",
    "3. Solve the localization task using regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T06:22:34.804777Z",
     "start_time": "2022-11-03T06:22:29.766932Z"
    },
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T06:23:13.242836Z",
     "start_time": "2022-11-03T06:23:03.342019Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0))) # plt accepts images in the format (w,h,c)\n",
    "    \n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "print(\"Image shape: \", images[0].shape)\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[:4]))\n",
    "# print labels\n",
    "print(' '.join('%10s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Construct a CNN in PyTorch\n",
    "\n",
    "In the following class, initiate your different layers in the `__init__` method and define your architecture in the `forward` method. Make sure the `forward` method has a single return value. \n",
    "\n",
    "1. Make good use of the documentation and experiment will different layers, activations and architectures, batch sizes, regularization, filter sizes, dimensions, number of layers and whatever you learned in class. \n",
    "2. Use your intuition from the previous exercises and additional sources such as the stackoverflow, Medium, etc. - **do not try to perform a massive grid search.**\n",
    "3. **Include only your chosen architecture**. During experimentation, you may add as many cells as you need. Make sure to delete them before submission.\n",
    "4. It is not allowed to use famous models that have been already implemented by PyTorch (resnet, densenet, alexnet, etc).\n",
    "5. Make sure your code runs reasonably fast (no more than 15 minutes on CPU).\n",
    "6. Use the best architecture you find and train it for 1-10 epochs. \n",
    "7. Visualize the loss and accuracy of your network during training. You can use matplotlib.\n",
    "8. You should get above 60% accuracy on the test set.\n",
    "**(20 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 12, 32, 32]          336\n",
      "├─MaxPool2d: 1-2                         [-1, 12, 16, 16]          --\n",
      "├─Conv2d: 1-3                            [-1, 24, 16, 16]          2,616\n",
      "├─MaxPool2d: 1-4                         [-1, 24, 8, 8]            --\n",
      "├─Conv2d: 1-5                            [-1, 24, 6, 6]            5,208\n",
      "├─MaxPool2d: 1-6                         [-1, 24, 3, 3]            --\n",
      "├─Linear: 1-7                            [-1, 120]                 26,040\n",
      "├─Linear: 1-8                            [-1, 60]                  7,260\n",
      "├─Linear: 1-9                            [-1, 10]                  610\n",
      "==========================================================================================\n",
      "Total params: 42,070\n",
      "Trainable params: 42,070\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 1.22\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.15\n",
      "Params size (MB): 0.16\n",
      "Estimated Total Size (MB): 0.32\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\n├─Conv2d: 1-1                            [-1, 12, 32, 32]          336\n├─MaxPool2d: 1-2                         [-1, 12, 16, 16]          --\n├─Conv2d: 1-3                            [-1, 24, 16, 16]          2,616\n├─MaxPool2d: 1-4                         [-1, 24, 8, 8]            --\n├─Conv2d: 1-5                            [-1, 24, 6, 6]            5,208\n├─MaxPool2d: 1-6                         [-1, 24, 3, 3]            --\n├─Linear: 1-7                            [-1, 120]                 26,040\n├─Linear: 1-8                            [-1, 60]                  7,260\n├─Linear: 1-9                            [-1, 10]                  610\n==========================================================================================\nTotal params: 42,070\nTrainable params: 42,070\nNon-trainable params: 0\nTotal mult-adds (M): 1.22\n==========================================================================================\nInput size (MB): 0.01\nForward/backward pass size (MB): 0.15\nParams size (MB): 0.16\nEstimated Total Size (MB): 0.32\n=========================================================================================="
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #############################################################################\n",
    "        # TO DO:                                                                    #\n",
    "        # Initiate the different layers you wish to use in your network.            #\n",
    "        # This method has no return value.                                          #\n",
    "        #############################################################################\n",
    "        self.bn1 = nn.BatchNorm2d(3)\n",
    "        self.conv1 = nn.Conv2d(3, 12, kernel_size=3, padding='same')\n",
    "        self.conv2 = nn.Conv2d(12, 24, kernel_size=3, padding='same')\n",
    "        self.conv3 = nn.Conv2d(24, 24, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(3*3*24, 120)\n",
    "        #self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc2 = nn.Linear(120, 60)\n",
    "        self.fc3 = nn.Linear(60, 10)\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        #############################################################################\n",
    "        # TO DO:                                                                    #\n",
    "        # Define the forward propagation. You need to pass an image through the     #\n",
    "        # network and obtain class predictions.                                     #\n",
    "        # This function returns the predication of your model.                      #\n",
    "        #############################################################################\n",
    "        #x = self.bn1(x)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool1(x)\n",
    "        #x = self.conv2_drop(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "\n",
    "criterion = None\n",
    "optimizer = None\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "#device = \"cpu\"\n",
    "net = Net().to(device)\n",
    "#############################################################################\n",
    "# TO DO:                                                                    #\n",
    "# Define the loss function and optimizer.                                   #\n",
    "#############################################################################\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################\n",
    "\n",
    "summary(net, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   782] loss: 0.764775276184082\n",
      "[2,   782] loss: 0.6747224926948547\n",
      "[3,   782] loss: 1.1174430847167969\n",
      "[4,   782] loss: 1.3999967575073242\n",
      "[5,   782] loss: 0.7640809416770935\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "# TO DO:                                                                    #\n",
    "# Define the training loop as seen in class and as demonstrated in the      #\n",
    "# documentation. Note, if you are using GPU, make sure your code runs on    #\n",
    "# CPU also. Code that cannot run will not be tested.                        # \n",
    "#############################################################################\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'[{epoch + 1}, {i + 1:5d}] loss: {loss.item()}')\n",
    "\n",
    "        # # print statistics\n",
    "        # running_loss += loss.item()\n",
    "        # if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "        #     print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "        #     running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model evaluation\n",
    "\n",
    "Calculate the model accuracy and print a confusion matrix where in y axis represents the real category and the x axis represents the predicted category. **(10 points)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on 10000 test images: 67.93%\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = np.zeros([10,10], int)\n",
    "model_accuracy = 0\n",
    "#############################################################################\n",
    "# TO DO:                                                                    #\n",
    "# Define the evaluation loop as seen in class and as demonstrated in the    #\n",
    "# documentation and use the confusion matrix to evaluate your model.        # \n",
    "#############################################################################\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(inputs)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "model_accuracy = (correct / total) * 100\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################\n",
    "print('Model accuracy on {0} test images: {1:.2f}%'.format(len(testset), model_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(8,6))\n",
    "ax.matshow(confusion_matrix, aspect='auto', vmin=0, vmax=1000, cmap=plt.get_cmap('Blues'))\n",
    "plt.ylabel('Actual Category')\n",
    "plt.yticks(range(10), classes)\n",
    "plt.xlabel('Predicted Category')\n",
    "plt.xticks(range(10), classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T06:36:16.100449Z",
     "start_time": "2022-11-03T06:36:16.075931Z"
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##**Question:** \n",
    "Describe your experiments.\n",
    "What parameters have you experimented with? What works and what doesn't? Why?   **(5 Points)**\n",
    "\n",
    "**Your answer:** *Fill this in*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##**Question:** \n",
    "What can you learn from the confusion matrix? Why do you need additional evaluation methods other than accuracy? **(5 Points)**\n",
    "\n",
    "**Your answer:** *Fill this in*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Localization as Regression (60 points)\n",
    "\n",
    "In the next part, we will use a well known architecture called ResNet18 that was trained on ImageNet, a dataset far more rich than CIFAR10. ImageNet has 1,000 classes and 1,000,000 images. In this part, we will use the features extracted from ResNet18 to localize and classify images of cats and dogs. \n",
    "\n",
    "Using a pretrained network as a building block for a more complicated task is at the heart of neural networks today. By leveraging the features ResNet18 extracts, we can train a model that can correctly classify and localize cats and dogs using very few images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T06:47:54.427755Z",
     "start_time": "2022-11-03T06:47:54.378583Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from data.dataloader import *\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import collections\n",
    "import time\n",
    "import copy\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To load ResNet18 with the pretrained weights, use the following line. You are welcome to try different architectures, however they might require different input sizes or normalization.\n",
    "\n",
    "The first time you run this cell the weights will be downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T06:47:56.251852Z",
     "start_time": "2022-11-03T06:47:55.703790Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resnet18 = resnet18(weights=ResNet18_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ResNet takes as input images of size (224,224). We will use PyTorch Transforms to change the size of the images. When ResNet18 was trained on ImageNet, the images were normalized using the mean and standard deviation of the images. In order to properly use the weights, we will use the same normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T06:48:50.701015Z",
     "start_time": "2022-11-03T06:48:50.645749Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        Rescale((224,224)),\n",
    "        ToTensor(),\n",
    "        Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # normalizing according to imagenet\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        Rescale((224,224)),\n",
    "        ToTensor(),\n",
    "        Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "root_dir = \"data/animals/\"\n",
    "datasets = {x: VOCDetection(root_dir, image_set=x, transform=data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=32, shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(datasets[x]) for x in ['train', 'val']}\n",
    "classes = datasets['train'].classes\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T06:48:59.538834Z",
     "start_time": "2022-11-03T06:48:55.845410Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "sample = next(iter(dataloaders['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T13:42:45.176992Z",
     "start_time": "2022-11-03T13:42:44.466434Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(img, label, bbox):\n",
    "    image = np.copy(img[0])\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "    image *= np.array([0.229, 0.224, 0.225])\n",
    "    image += np.array([0.485, 0.456, 0.406])\n",
    "    label = label[0]\n",
    "    bbox = bbox[0]\n",
    "    plt.figure();\n",
    "    fig, ax = plt.subplots(1, figsize=(12,9));\n",
    "    ax.imshow(image);\n",
    "    x1, y1, x2, y2 = bbox.numpy().reshape(-1) * 224\n",
    "    box_w, box_h = np.abs(x2-x1), np.abs(y2-y1)\n",
    "    bbox = patches.Rectangle((x1, y1), box_w, box_h, linewidth=2, \n",
    "                             edgecolor='r', facecolor='none');\n",
    "    ax.add_patch(bbox);\n",
    "    ax.annotate(classes[label], (x1, y1), color='r', fontsize=14);\n",
    "\n",
    "imshow(sample['image'],sample['label'],sample['bbox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T13:42:48.611496Z",
     "start_time": "2022-11-03T13:42:48.580819Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        #############################################################################\n",
    "        # TO DO:                                                                    #\n",
    "        # Load the pretrained ResNet-18 network and replace the top fully connected #\n",
    "        # layer, so we could use the features of the network and not the only      #\n",
    "        # the classification layer which carries significantly less information.    #\n",
    "        # Afterwards, create a new sequential model with the remaining layers of    #\n",
    "        # the pretrained network. Next, define two additional models that take as   #\n",
    "        # input the extracted features and output the class scores and bounding box #\n",
    "        # coordinates.                                                              #\n",
    "        # This function has no return value.                                        #\n",
    "        #############################################################################\n",
    "        pass\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "    \n",
    "    def forward(self, images):\n",
    "        #############################################################################\n",
    "        # TO DO:                                                                    #\n",
    "        # Define the forward propagation. You need to pass an image through the     #\n",
    "        # network and extract the feature vector. In this case, when using a        #\n",
    "        # predefined network, you don't want to change it's weights.                #\n",
    "        # The rest of the layers you defined should accepts gradients for them to   #\n",
    "        # improve during training.                                                  #\n",
    "        # This function returns a class predication and a bounding box coordinates. #\n",
    "        #############################################################################\n",
    "        pass\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Guidelines\n",
    "\n",
    "1. Complete the `train_model` function in the cell below. This function takes as input the model and additional hyper-parameters, and outputs the best model found on the validation set. \n",
    "2. To babysit the learning process, **you must track the classification accuracy, IoU score and loss on the training and validation datasets and visualize them** (using matplotlib or similar). I have included an implementation of the IoU metric in the file `data\\dataloader.py`.\n",
    "3. Do not perform a massive grid search. Use papers, blogs, MOOCs and online guides to research best hyper-parameters for your model.\n",
    "4. You are encouraged to try Google Colab. If you have an CUDA capable GPU at home - you are welcome to use it.\n",
    "5. **Include only your chosen architecture**. During experimentation, you may add as many cells as you need. Make sure to delete them before submission.\n",
    "6. Training large neural networks may take a while. Make sure your code runs reasonably fast (~15 minutes on CPU and ~5 minutes on GPU).\n",
    "7. Try to reach at least 90% classification accuracy and a IOU score of at least 0.60 on the validation set.\n",
    "8. **In order to get full marks for this section explain the results and include visualizations.**.\n",
    "9. You are given a general skeleton for the training function. Feel free to use any different structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T13:42:50.832283Z",
     "start_time": "2022-11-03T13:42:50.792639Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion_cls, criterion_bbox, optimizer, scheduler=None, num_epochs=5):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict()) # this is how a model is copied\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0   # total loss of the network at each epoch\n",
    "            running_corrects = 0 # number of correct predictions\n",
    "            iou = 0.0            # IoU score\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for sample in dataloaders[phase]:\n",
    "                #############################################################################\n",
    "                # TO DO:                                                                    #\n",
    "                # Extract the data from the dataloader, calculate the predictions of your   #\n",
    "                # network and calculate the loss of the classification and bounding box     #\n",
    "                # prediction. When in training mode, back-prop and update the weights.      #\n",
    "                # At each epoch, calculate the test and train accuracy and IoU.             #\n",
    "                # This function returns the best model in terms of accuracy.                #\n",
    "                #############################################################################\n",
    "                pass\n",
    "                #############################################################################\n",
    "                #                             END OF YOUR CODE                              #\n",
    "                #############################################################################\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            iou = iou.item() / dataset_sizes[phase]\n",
    "            \n",
    "            print('{} Loss: {:.4f}  |  Acc: {:.4f}  |  IOU: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc, iou))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Choose your optimizer and the loss functions for the classification and bounding box regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T13:42:53.965679Z",
     "start_time": "2022-11-03T13:42:53.933546Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "cnn = CNN(2)\n",
    "cnn = cnn.to(device)\n",
    "\n",
    "criterion_cls = None\n",
    "criterion_bbox = None\n",
    "optimizer = None\n",
    "#############################################################################\n",
    "#                           START OF YOUR CODE                              #\n",
    "#############################################################################\n",
    "pass\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_model = train_model(cnn, criterion_cls, criterion_bbox, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once you are pleased with your results, see how your model can predict and localize cats and dogs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get a batch of validation data\n",
    "sample = next(iter(dataloaders['val']))\n",
    "with torch.no_grad():\n",
    "    images = sample['image']\n",
    "    images = images.to(device)\n",
    "    label_pred, bbox_pred = best_model(images)\n",
    "    _, label_pred = torch.max(label_pred, 1)\n",
    "imshow(sample['image'], label_pred.cpu(), bbox_pred.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Your visualizations here (IoU / Accuracy / Loss on training and validation datasets as a function of the epoch). Only visualize the results of your best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}